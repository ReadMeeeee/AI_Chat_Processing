# AI_Chat_processing

Практический проект: пайплайн обработки документов **.docx → структурированный .json** с использованием LLM.

В данной версии практика реализована через **несколько запросов к модели**  
(отдельный запрос на каждый пункт задачи), что упрощает контроль логики,  
но приводит к **избыточному расходу токенов**. Этот недостаток осознан и
планируется к исправлению в следующих версиях проекта.


## Идея проекта

Вход: `.docx`  
Выход: `.json`

Общий сценарий:
1. загрузка и чтение `.docx`
2. очистка и подготовка текста
3. последовательная отправка нескольких конкурентных запросов в LLM  
   (каждый запрос соответствует отдельному пункту задачи)
4. агрегация ответов
5. сохранение результата в JSON

Подробное описание логики и шагов обработки приведено в
`solution_presentation.ipynb`.


## Как устроен запуск

Точка входа проекта - `solution/run.py`.

```python
model = deepseek_api
process_all_chats(
    model=model,
    path_to_input=path_to_input_data,
    path_to_process=path_to_process,
    path_to_instruct=path_to_instruct_json,
    path_to_output=path_to_output
)
```
На уровне конфигурации выбирается модель (например, deepseek_api
или chatgpt_api), а также пути к входным данным, инструкциям и выходному файлу.


## Архитектура проекта
Основные модули:

`solution/run.py` - Точка входа, инициализация модели и запуск полного пайплайна.
`solution/chats_process/`
    `chats_process.py` - последовательная обработка всех пунктов задачи (несколько LLM-запросов, сбор ответов).
`solution/file_io/`
    `docx_loader.py` - загрузка и извлечение текста из .docx
    `json_loader.py` - чтение и запись JSON
    `txt_writer.py` - вспомогательный вывод текстовых данных
`solution/processing/`
    `cleaner.py` - очистка и нормализация текста
    `formatter.py` - подготовка данных под запросы и итоговый JSON
    `llm_api.py` - слой взаимодействия с LLM
    `processing.py` - основной пайплайн обработки
`solution/models/`
`models.py` - структуры данных и модели
`solution/config/`
    `config.py` - конфигурация проекта (модель, пути, параметры)
    `prompt_data.json` - инструкции / данные для промптов
`solution_presentation.ipynb` - Подробное описание хода выполнения и логики проекта.


## Особенность текущей версии (ВАЖНО)
В этой версии проекта:
каждый пункт задачи обрабатывается отдельным запросом к LLM;
это упрощает реализацию и отладку;
но приводит к избыточной трате токенов.
Данный подход выбран осознанно для практики и будет оптимизирован
в следующих версиях (объединением пунктов в один запрос
или переходом к агентной архитектуре).


## Запуск
```bash
pip install -r requirements.txt
python -m python -m solution.run
```

Все пути и параметры задаются в solution/config/config.py
